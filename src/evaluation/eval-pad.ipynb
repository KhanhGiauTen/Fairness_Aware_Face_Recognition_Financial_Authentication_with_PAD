{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8639156,"sourceType":"datasetVersion","datasetId":5173700},{"sourceId":13556550,"sourceType":"datasetVersion","datasetId":8610650},{"sourceId":616212,"sourceType":"modelInstanceVersion","modelInstanceId":463186,"modelId":478967},{"sourceId":616219,"sourceType":"modelInstanceVersion","modelInstanceId":463192,"modelId":478973},{"sourceId":623100,"sourceType":"modelInstanceVersion","modelInstanceId":463192,"modelId":478973}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# C√†i ƒë·∫∑t th∆∞ vi·ªán c·∫ßn thi·∫øt\n!pip install -q ultralytics kagglehub scikit-learn seaborn transformers\n!pip install \"numpy<2.0\" \"scipy<1.14\" \"matplotlib>=3.8,<3.9\" seaborn scikit-learn\n\n# Import c√°c th∆∞ vi·ªán\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.models as models\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader, Dataset\n# B·ªé import torchvision ViT\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\nimport os\nimport sys\nimport yaml\nimport math\nimport logging\nimport kagglehub\nfrom tqdm.notebook import tqdm\nfrom pathlib import Path\nfrom ultralytics import YOLO\n\n# (S·ª¨A ƒê·ªîI) Import ƒë√∫ng model ViT t·ª´ transformers\nfrom transformers import ViTImageProcessor, ViTForImageClassification\n\n# Import c√°c h√†m t√≠nh to√°n metrics\nfrom sklearn.metrics import roc_curve, auc, confusion_matrix, accuracy_score, f1_score, roc_auc_score\nfrom scipy.optimize import brentq\nfrom scipy.interpolate import interp1d\n\n# Thi·∫øt l·∫≠p logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(message)s')\nlogger = logging.getLogger(__name__)\n\n# Thi·∫øt b·ªã\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"S·ª≠ d·ª•ng thi·∫øt b·ªã: {device}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-31T13:53:36.563869Z","iopub.execute_input":"2025-10-31T13:53:36.564185Z","iopub.status.idle":"2025-10-31T13:55:49.484119Z","shell.execute_reply.started":"2025-10-31T13:53:36.564159Z","shell.execute_reply":"2025-10-31T13:55:49.483333Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.6 which is incompatible.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.3 which is incompatible.\nmkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\nmkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\nmkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\nnumba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\nydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.2.6 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\npandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\ntensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\numap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mCollecting numpy<2.0\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting scipy<1.14\n  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting matplotlib<3.9,>=3.8\n  Downloading matplotlib-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.12.2)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.9,>=3.8) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.9,>=3.8) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.9,>=3.8) (4.59.0)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.9,>=3.8) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.9,>=3.8) (25.0)\nRequirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.9,>=3.8) (11.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.9,>=3.8) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.9,>=3.8) (2.9.0.post0)\nRequirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25->seaborn) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25->seaborn) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib<3.9,>=3.8) (1.17.0)\nDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading matplotlib-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: numpy, scipy, matplotlib\n  Attempting uninstall: numpy\n    Found existing installation: numpy 2.2.6\n    Uninstalling numpy-2.2.6:\n      Successfully uninstalled numpy-2.2.6\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.15.3\n    Uninstalling scipy-1.15.3:\n      Successfully uninstalled scipy-1.15.3\n  Attempting uninstall: matplotlib\n    Found existing installation: matplotlib 3.7.2\n    Uninstalling matplotlib-3.7.2:\n      Successfully uninstalled matplotlib-3.7.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\ntsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nopencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nopencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\npandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nopencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\numap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed matplotlib-3.8.4 numpy-1.26.4 scipy-1.13.1\nCreating new Ultralytics Settings v0.0.6 file ‚úÖ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761918936.548435      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761918936.599963      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"S·ª≠ d·ª•ng thi·∫øt b·ªã: cuda\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# H√†m ti·ªán √≠ch ƒë·ªÉ n·∫°p checkpoint (S·ª¨A L·ªñI: d√πng strict=True)\ndef load_checkpoint_to_model(model_instance: torch.nn.Module, checkpoint_path: str, device=None):\n    device = device or torch.device('cpu')\n    if not os.path.isfile(checkpoint_path):\n        raise FileNotFoundError(f\"File checkpoint kh√¥ng t·ªìn t·∫°i: {checkpoint_path}\")\n        \n    logger.info(f\"ƒêang n·∫°p checkpoint v√†o model t·ª´: {checkpoint_path}\")\n    checkpoint = torch.load(checkpoint_path, map_location=device)\n    state_dict = checkpoint.get('model_state_dict', checkpoint)\n\n    first_key = next(iter(state_dict.keys()), None)\n    if first_key is None:\n        raise ValueError(f\"State dict r·ªóng trong checkpoint: {checkpoint_path}\")\n        \n    is_data_parallel = first_key.startswith('module.')\n\n    if is_data_parallel:\n        logger.info(\"Ph√°t hi·ªán state_dict t·ª´ DataParallel, ƒëang lo·∫°i b·ªè ti·ªÅn t·ªë 'module.'...\")\n        state_dict = {k.replace('module.', '', 1): v for k, v in state_dict.items()}\n    \n    # (S·ª¨A L·ªñI) D√πng strict=True ƒë·ªÉ ƒë·∫£m b·∫£o n·∫°p ƒë√∫ng ki·∫øn tr√∫c\n    load_result = model_instance.load_state_dict(state_dict, strict=True) \n    logger.info(f\"K·∫øt qu·∫£ load state dict (strict=True): {load_result}\") \n\n    # model_instance = torch.nn.DataParallel(model_instance)\n    model_instance.to(device)\n    model_instance.eval()\n    logger.info(\"N·∫°p checkpoint th√†nh c√¥ng.\")\n    return model_instance\n\nprint(\"ƒê√£ ƒë·ªãnh nghƒ©a h√†m load_checkpoint_to_model (strict=True).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T13:55:49.485719Z","iopub.execute_input":"2025-10-31T13:55:49.486202Z","iopub.status.idle":"2025-10-31T13:55:49.492749Z","shell.execute_reply.started":"2025-10-31T13:55:49.486183Z","shell.execute_reply":"2025-10-31T13:55:49.492090Z"}},"outputs":[{"name":"stdout","text":"ƒê√£ ƒë·ªãnh nghƒ©a h√†m load_checkpoint_to_model (strict=True).\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# --- ƒêƒÉng nh·∫≠p Kaggle Hub ---\ntry:\n    print(\"ƒêang ƒëƒÉng nh·∫≠p Kaggle Hub...\")\n    kagglehub.login()\n    print(\"Kaggle Hub login th√†nh c√¥ng.\")\nexcept Exception as e:\n    logger.warning(f\"Kaggle Hub login l·ªói/b·ªè qua: {e}.\")\n\n# --- ƒê·ªãnh nghƒ©a Handle ---\nYOLO_HANDLE = \"khnhnguyn222/yolo-facedetection/pyTorch/default\"\nVIT_HANDLE = \"khnhnguyn222/vision-transformer/pytorch/default/1\"\n\n# (S·ª¨A L·ªñI) S·ª¨A T√äN FILE TH√ÄNH CHECKPOINT ƒê√öNG\nVIT_FILENAME = \"ViT.pt\" # T√™n file 97.74% Acc\n\nNUM_VIT_CLASSES = 2 \nMODEL_STR = \"google/vit-base-patch16-224-in21k\" # D√πng ƒë·ªÉ l·∫•y ki·∫øn tr√∫c g·ªëc\n\n# --- T·∫£i Model YOLO ---\ntry:\n    print(f\"ƒêang t·∫£i YOLO t·ª´: {YOLO_HANDLE}\")\n    yolo_model_dir = kagglehub.model_download(YOLO_HANDLE)\n    yolo_model_path = os.path.join(yolo_model_dir, \"YOLO.pt\") \n    if not os.path.exists(yolo_model_path):\n        pt_files = [f for f in os.listdir(yolo_model_dir) if f.endswith(\".pt\")]\n        yolo_model_path = os.path.join(yolo_model_dir, pt_files[0])\n    yolo_model = YOLO(yolo_model_path)\n    # yolo_model = torch.nn.DataParallel(yolo_model)\n    yolo_model.to(device) \n    print(f\"T·∫£i YOLO model th√†nh c√¥ng t·ª´: {yolo_model_path}\")\nexcept Exception as e:\n    logger.error(f\"L·ªói khi t·∫£i YOLO: {e}\"); raise e\n\n# --- (S·ª¨A L·ªñI KI·∫æN TR√öC) T·∫£i Model ViT (PAD) ---\ntry:\n    print(f\"ƒêang t·∫£i ViT t·ª´: {VIT_HANDLE} (file: {VIT_FILENAME})\")\n    vit_model_dir = kagglehub.model_download(VIT_HANDLE)\n    vit_model_path = os.path.join(vit_model_dir, VIT_FILENAME) \n    if not os.path.exists(vit_model_path):\n         raise FileNotFoundError(f\"Kh√¥ng t√¨m th·∫•y file {VIT_FILENAME} trong th∆∞ m·ª•c ViT. H√£y ki·ªÉm tra l·∫°i t√™n file tr√™n Kaggle Hub.\")\n\n    # Kh·ªüi t·∫°o ki·∫øn tr√∫c HUGGING FACE (gi·ªëng l√∫c train)\n    vit_model = ViTForImageClassification.from_pretrained(\n        MODEL_STR, \n        num_labels=NUM_VIT_CLASSES \n    )\n    \n    # Load state_dict t·ª´ checkpoint .pt ƒë√£ train\n    load_checkpoint_to_model(vit_model, vit_model_path, device=device)\n    print(f\"T·∫£i ViT (PAD) model (Transformers) th√†nh c√¥ng t·ª´: {vit_model_path}\")\n    \nexcept Exception as e:\n    logger.error(f\"L·ªói khi t·∫£i ViT: {e}\")\n    raise e\n\nprint(\"\\n--- T·∫£i t·∫•t c·∫£ Model cho ƒë√°nh gi√° PAD th√†nh c√¥ng! ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T13:55:49.493616Z","iopub.execute_input":"2025-10-31T13:55:49.493872Z","iopub.status.idle":"2025-10-31T13:56:03.305821Z","shell.execute_reply.started":"2025-10-31T13:55:49.493848Z","shell.execute_reply":"2025-10-31T13:56:03.305111Z"}},"outputs":[{"name":"stdout","text":"ƒêang ƒëƒÉng nh·∫≠p Kaggle Hub...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggle‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ca9b0c12e224a27bafeab3ac3c34b28"}},"metadata":{}},{"name":"stdout","text":"Kaggle Hub login th√†nh c√¥ng.\nƒêang t·∫£i YOLO t·ª´: khnhnguyn222/yolo-facedetection/pyTorch/default\nT·∫£i YOLO model th√†nh c√¥ng t·ª´: /kaggle/input/yolo-facedetection/pytorch/default/1/YOLO.pt\nƒêang t·∫£i ViT t·ª´: khnhnguyn222/vision-transformer/pytorch/default/1 (file: ViT.pt)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcf270209974481dbb57c9bb111408ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90d701ccd0ea4541adb8c8ce2ba905e5"}},"metadata":{}},{"name":"stderr","text":"Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"T·∫£i ViT (PAD) model (Transformers) th√†nh c√¥ng t·ª´: /kaggle/input/vision-transformer/pytorch/default/1/ViT.pt\n\n--- T·∫£i t·∫•t c·∫£ Model cho ƒë√°nh gi√° PAD th√†nh c√¥ng! ---\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# L·ªõp Dataset cho CelebA-Spoof\nclass CelebASpoofDataset(Dataset):\n    def __init__(self, root_dir, meta_file, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform \n        self.samples = []\n        with open(meta_file, \"r\") as f:\n            for line in f:\n                path, label = line.strip().split()\n                img_path = os.path.join(root_dir, path)\n                label = int(label)\n                if os.path.exists(img_path):\n                    self.samples.append((img_path, label))\n        print(f\"Loaded {len(self.samples)} samples from {meta_file}\")\n    def __len__(self): return len(self.samples)\n    def __getitem__(self, idx): return self.samples[idx]\n\nprint(\"ƒê√£ ƒë·ªãnh nghƒ©a CelebASpoofDataset.\")\n\n# --- (S·ª¨A L·ªñI) L·∫•y Processor/Transform ƒë√∫ng (gi·ªëng l√∫c train) ---\ntry:\n    processor = ViTImageProcessor.from_pretrained(MODEL_STR)\n    logger.info(f\"ƒê√£ t·∫£i processor t·ª´ {MODEL_STR}\")\nexcept Exception as e:\n    logger.error(f\"Kh√¥ng th·ªÉ t·∫£i ViTImageProcessor: {e}.\")\n    raise e\n\nvit_transform = transforms.Compose([\n    transforms.ToPILImage(), \n    transforms.Resize((processor.size[\"height\"], processor.size[\"height\"])),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=processor.image_mean, std=processor.image_std)\n])\nprint(\"ƒê√£ ƒë·ªãnh nghƒ©a vit_transform (d·ª±a tr√™n ViTImageProcessor).\")\n\n# --- ƒê∆∞·ªùng d·∫´n D·ªØ li·ªáu (tr√™n Kaggle) ---\nCELEBA_ROOT_DIR = \"/kaggle/input/celeba-spoofing/CelebA_Spoof\"\nCELEBA_TEST_META = os.path.join(CELEBA_ROOT_DIR, \"metas/intra_test/test_label.txt\")\n\nif not os.path.exists(CELEBA_TEST_META):\n    logger.error(f\"KH√îNG T√åM TH·∫§Y FILE TEST META: {CELEBA_TEST_META}\")\n    raise FileNotFoundError(f\"Kh√¥ng t√¨m th·∫•y file test meta: {CELEBA_TEST_META}\")\n\n# --- T·∫°o Test Loader ---\npad_test_dataset = CelebASpoofDataset(\n    root_dir=CELEBA_ROOT_DIR, \n    meta_file=CELEBA_TEST_META, \n    transform=vit_transform # G√°n transform ƒë√∫ng\n)\n\npad_test_loader = DataLoader(\n    pad_test_dataset, \n    batch_size=32, \n    shuffle=False, \n    num_workers=2\n)\n\nprint(f\"S·∫µn s√†ng ƒë√°nh gi√° PAD tr√™n {len(pad_test_dataset)} m·∫´u test.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T13:56:03.306908Z","iopub.execute_input":"2025-10-31T13:56:03.307256Z","iopub.status.idle":"2025-10-31T14:00:13.831977Z","shell.execute_reply.started":"2025-10-31T13:56:03.307226Z","shell.execute_reply":"2025-10-31T14:00:13.831229Z"}},"outputs":[{"name":"stdout","text":"ƒê√£ ƒë·ªãnh nghƒ©a CelebASpoofDataset.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a74d995e6c604ffaae7a915cee31ff5c"}},"metadata":{}},{"name":"stdout","text":"ƒê√£ ƒë·ªãnh nghƒ©a vit_transform (d·ª±a tr√™n ViTImageProcessor).\nLoaded 67170 samples from /kaggle/input/celeba-spoofing/CelebA_Spoof/metas/intra_test/test_label.txt\nS·∫µn s√†ng ƒë√°nh gi√° PAD tr√™n 67170 m·∫´u test.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"def calculate_pad_metrics(y_true, y_scores, y_preds):\n    \"\"\"T√≠nh to√°n Acc, F1, ROC AUC, APCER, BPCER, v√† ACER.\"\"\"\n    y_true = np.array(y_true)\n    y_scores = np.array(y_scores) # X√°c su·∫•t spoof (l·ªõp 1)\n    y_preds = np.array(y_preds)   # Nh√£n d·ª± ƒëo√°n (0 ho·∫∑c 1)\n    \n    # y_true: 0 = LIVE (Bona Fide), 1 = SPOOF (Attack)\n    \n    acc = accuracy_score(y_true, y_preds)\n    f1 = f1_score(y_true, y_preds, zero_division=0)\n    try:\n        roc_auc = roc_auc_score(y_true, y_scores)\n    except ValueError:\n        roc_auc = 0.0 \n\n    live_indices = np.where(y_true == 0)[0]\n    spoof_indices = np.where(y_true == 1)[0]\n    \n    total_live = len(live_indices)\n    total_spoof = len(spoof_indices)\n\n    if total_live == 0 or total_spoof == 0:\n        logger.warning(\"T·∫≠p k·∫øt qu·∫£ ch·ªâ ch·ª©a 1 l·ªõp. Kh√¥ng th·ªÉ t√≠nh APCER/BPCER.\")\n        return {\"Accuracy\": acc, \"F1-Score\": f1, \"ROC AUC\": roc_auc, \"APCER\": 0, \"BPCER\": 0, \"ACER\": 0}, None\n\n    # BPCER: T·ª∑ l·ªá LIVE b·ªã ph√¢n lo·∫°i nh·∫ßm l√† SPOOF (False Positive)\n    bpcer_errors = np.sum(y_preds[live_indices] == 1)\n    bpcer = bpcer_errors / total_live if total_live > 0 else 0.0\n    \n    # APCER: T·ª∑ l·ªá SPOOF b·ªã ph√¢n lo·∫°i nh·∫ßm l√† LIVE (False Negative)\n    apcer_errors = np.sum(y_preds[spoof_indices] == 0)\n    apcer = apcer_errors / total_spoof if total_spoof > 0 else 0.0\n    \n    # ACER: Trung b√¨nh\n    acer = (apcer + bpcer) / 2.0\n    \n    cm = confusion_matrix(y_true, y_preds, labels=[0, 1]) # ƒê·∫£m b·∫£o th·ª© t·ª± 0, 1\n    \n    metrics = {\n        \"Accuracy\": acc,\n        \"F1-Score\": f1,\n        \"ROC AUC\": roc_auc,\n        \"APCER (T·∫•n c√¥ng b·ªã l·ªçt)\": apcer, \n        \"BPCER (Ng∆∞·ªùi th·∫≠t b·ªã t·ª´ ch·ªëi)\": bpcer, \n        \"ACER (L·ªói trung b√¨nh)\": acer\n    }\n    return metrics, cm\n\ndef plot_roc_curve_pad(y_true, y_scores, title):\n    \"\"\"V·∫Ω ƒë∆∞·ªùng cong ROC.\"\"\"\n    fpr, tpr, thresholds = roc_curve(y_true, y_scores, pos_label=1)\n    roc_auc = auc(fpr, tpr)\n\n    plt.figure(figsize=(8, 6))\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:0.3f})')\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate (FPR) / BPCER')\n    plt.ylabel('True Positive Rate (TPR)')\n    plt.title(title)\n    plt.legend(loc=\"lower right\")\n    plt.grid(True)\n    plt.show()\n\ndef plot_confusion_matrix_pad(cm, title=\"Confusion Matrix (PAD)\"):\n    \"\"\"Plot the confusion matrix for Presentation Attack Detection (PAD).\"\"\"\n    if cm is None or cm.shape != (2, 2):\n        logger.warning(f\"Invalid confusion matrix: {cm}. Skipping plot.\")\n        if cm is not None and cm.shape == (1, 1):\n            if len(np.unique(pad_labels)) == 1 and np.unique(pad_labels)[0] == 0:\n                cm = np.array([[cm[0, 0], 0], [0, 0]])\n            else:\n                cm = np.array([[0, 0], [0, cm[0, 0]]])\n        else:\n            return\n\n    labels_axis = ['Live', 'Spoof']\n    columns_axis = ['Live', 'Spoof']\n    \n    cm_sum = cm.sum(axis=1)[:, np.newaxis]\n    cm_percent = np.nan_to_num(cm.astype('float') / cm_sum)\n    hm_labels = [f\"{count}\\n{perc*100:0.2f}%\" for count, perc in zip(cm.flatten(), cm_percent.flatten())]\n    hm_labels = np.asarray(hm_labels).reshape(2, 2)\n    \n    plt.figure(figsize=(8, 6))\n    sns.heatmap(\n        cm, annot=hm_labels, fmt='', cmap='Blues',\n        xticklabels=columns_axis, yticklabels=labels_axis\n    )\n    plt.title(title)\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    plt.show()\n\n\nprint(\"ƒê√£ ƒë·ªãnh nghƒ©a c√°c h√†m t√≠nh to√°n v√† v·∫Ω metrics PAD.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T14:00:13.832831Z","iopub.execute_input":"2025-10-31T14:00:13.833126Z","iopub.status.idle":"2025-10-31T14:00:13.846939Z","shell.execute_reply.started":"2025-10-31T14:00:13.833100Z","shell.execute_reply":"2025-10-31T14:00:13.846293Z"}},"outputs":[{"name":"stdout","text":"ƒê√£ ƒë·ªãnh nghƒ©a c√°c h√†m t√≠nh to√°n v√† v·∫Ω metrics PAD.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def run_pad_evaluation(yolo_model, vit_model, loader, transform, device):\n    vit_model.eval()\n    all_labels = []\n    all_scores = [] # X√°c su·∫•t Spoof (l·ªõp 1)\n    all_preds = []  # Nh√£n d·ª± ƒëo√°n (0 ho·∫∑c 1)\n    logger.info(\"B·∫Øt ƒë·∫ßu ch·∫°y ƒë√°nh gi√° PAD tr√™n t·∫≠p test...\")\n    pad_threshold = 0.5 # D√πng argmax\n    \n    for batch_paths, batch_labels in tqdm(loader, desc=\"ƒê√°nh gi√° PAD (ViT)\"):\n        batch_labels = batch_labels.numpy()\n        \n        for idx, img_path in enumerate(batch_paths):\n            true_label = batch_labels[idx]\n            try:\n                # 1. ƒê·ªçc ·∫£nh\n                image_bgr = cv2.imread(img_path)\n                if image_bgr is None: continue\n                image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n                \n                # 2. Ch·∫°y YOLO\n                yolo_results = yolo_model(image_rgb, verbose=False, conf=0.5)\n                detections = yolo_results[0].boxes\n                if len(detections) == 0: continue\n\n                # 3. L·∫•y box l·ªõn nh·∫•t\n                best_box = max(detections, key=lambda box: (box.xyxy[0][2]-box.xyxy[0][0])*(box.xyxy[0][3]-box.xyxy[0][1]))\n                x1, y1, x2, y2 = best_box.xyxy[0].int().tolist()\n                face_crop_rgb = image_rgb[y1:y2, x1:x2]\n                if face_crop_rgb.shape[0] < 10 or face_crop_rgb.shape[1] < 10: continue\n                \n                # 4. √Åp d·ª•ng transform (d√πng transform c·ªßa transformers)\n                vit_input_tensor = transform(face_crop_rgb).unsqueeze(0).to(device)\n                \n                with torch.no_grad():\n                    # (S·ª¨A L·ªñI) G·ªçi model transformers\n                    outputs = vit_model(vit_input_tensor) \n                    vit_logits = outputs.logits # L·∫•y logits t·ª´ output c·ªßa transformers\n                    \n                    vit_probs = F.softmax(vit_logits, dim=1)\n                    spoof_prob_vit = vit_probs[0, 1].item() \n                    vit_pred = vit_logits.argmax(-1).item() # L·∫•y argmax\n                \n                all_labels.append(true_label)\n                all_scores.append(spoof_prob_vit)\n                all_preds.append(vit_pred) \n                \n            except Exception as e_process:\n                logger.error(f\"L·ªói khi x·ª≠ l√Ω ·∫£nh {img_path}: {e_process}\")\n                continue\n                \n    logger.info(\"Ho√†n t·∫•t ƒë√°nh gi√° PAD.\")\n    return all_labels, all_scores, all_preds\n\n# --- Ch·∫°y ---\npad_labels, pad_scores, pad_preds = run_pad_evaluation(\n    yolo_model, \n    vit_model, \n    pad_test_loader, \n    vit_transform, # Truy·ªÅn transform ƒë√∫ng (t·ª´ processor)\n    device\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T14:00:13.848676Z","iopub.execute_input":"2025-10-31T14:00:13.848879Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"ƒê√°nh gi√° PAD (ViT):   0%|          | 0/2100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13bc479e1204410993d52aededd9fe34"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"# --- T√≠nh to√°n v√† Hi·ªÉn th·ªã K·∫øt qu·∫£ ---\nif pad_labels:\n    logger.info(\"ƒêang t√≠nh to√°n c√°c ch·ªâ s·ªë PAD...\")\n    # T√≠nh metrics d·ª±a tr√™n d·ª± ƒëo√°n (pad_preds)\n    # y_scores (x√°c su·∫•t) ƒë∆∞·ª£c d√πng cho ROC AUC\n    pad_metrics, pad_cm = calculate_pad_metrics(pad_labels, pad_scores, pad_preds)\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"--- üìä K·∫æT QU·∫¢ ƒê√ÅNH GI√Å PAD (ViT TR√äN CELEBA-SPOOF TEST) ---\")\n    print(\"=\"*60)\n    \n    for metric, value in pad_metrics.items():\n        print(f\"{metric:<30}: {value:.4%}\") # ƒê·ªãnh d·∫°ng %\n    print(\"-\"*(60))\n    \n    # V·∫Ω bi·ªÉu ƒë·ªì\n    plot_roc_curve_pad(pad_labels, pad_scores, title=\"ROC Curve (ViT PAD)\")\n    plot_confusion_matrix_pad(pad_cm, title=\"Confusion Matrix (ViT PAD)\")\n\nelse:\n    logger.warning(\"Kh√¥ng c√≥ k·∫øt qu·∫£ n√†o ƒë·ªÉ t√≠nh to√°n (c√≥ th·ªÉ do l·ªói ƒë·ªçc d·ªØ li·ªáu ho·∫∑c YOLO kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c m·∫∑t).\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}